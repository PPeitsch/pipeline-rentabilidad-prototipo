{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Exploratorio y Limpieza de Datos (Refactorizado)"
      ],
      "metadata": {
        "id": "eY11WrpEqoGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuración de Entorno y Carga de Datos\n",
        "\n",
        "Se importan las librerías necesarias, se configura el entorno y se cargan los datos crudos desde el archivo CSV."
      ],
      "metadata": {
        "id": "tOTAbfYWriw3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZc1UHWypjl0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "# Add src directory to path to import our custom module\n",
        "sys.path.insert(0, '../src')\n",
        "from data_cleaner import run_cleaning_pipeline\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Mount Google Drive and define file path\n",
        "drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/My Drive/Colab Notebooks/test/rentabilidad_productos.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the raw dataset\n",
        "df_raw = pd.read_csv(file_path)\n",
        "print(f\"DataFrame crudo cargado con {df_raw.shape[0]} filas y {df_raw.shape[1]} columnas.\")\n",
        "display(df_raw.head())"
      ],
      "metadata": {
        "id": "4t74GQZQqriZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Análisis Exploratorio de Datos Crudos (EDA)\n",
        "\n",
        "Se explora el DataFrame original para identificar problemas de calidad de datos antes de la limpieza."
      ],
      "metadata": {
        "id": "75fx-KeWsKrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Tipos de Datos y Resumen General"
      ],
      "metadata": {
        "id": "SEpIrynjsuGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.info()"
      ],
      "metadata": {
        "id": "oHlYtznHs0f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Análisis de Valores Nulos"
      ],
      "metadata": {
        "id": "iy2TEtJzuZGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df_raw.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df_raw)) * 100\n",
        "missing_df = pd.DataFrame({'count': missing_values, 'percentage': missing_percentage})\n",
        "missing_df = missing_df[missing_df['count'] > 0].sort_values(by='count', ascending=False)\n",
        "\n",
        "print(f\"Se encontraron {len(missing_df)} columnas con valores nulos en los datos crudos.\")\n",
        "display(missing_df)\n",
        "\n",
        "msno.matrix(df_raw)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1-es6YLXuT7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Análisis de Duplicados en Clave Primaria (SKU)"
      ],
      "metadata": {
        "id": "CmmuR0dfuhf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to normalize column names first to access 'sku' reliably\n",
        "temp_df = df_raw.copy()\n",
        "temp_df.columns = temp_df.columns.str.strip().str.lower()\n",
        "\n",
        "sku_counts = temp_df.sku.value_counts()\n",
        "duplicated_skus = sku_counts[sku_counts > 1]\n",
        "\n",
        "print(f\"Análisis de duplicados de SKU:\")\n",
        "print(f\"- Hay {len(sku_counts)} SKUs únicos de un total de {len(temp_df)} registros.\")\n",
        "print(f\"- Se encontraron {len(duplicated_skus)} SKUs con registros duplicados.\")"
      ],
      "metadata": {
        "id": "iBL15PYRugq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Proceso de Limpieza de Datos\n",
        "\n",
        "Se invoca el pipeline de limpieza definido en el módulo `data_cleaner` para procesar el DataFrame."
      ],
      "metadata": {
        "id": "yx_8dH-lug67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = run_cleaning_pipeline(df_raw)"
      ],
      "metadata": {
        "id": "4lgtnlv6vaTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Verificación y Análisis de Datos Limpios\n",
        "\n",
        "Se realizan una serie de verificaciones y visualizaciones sobre el DataFrame limpio para asegurar la calidad del proceso."
      ],
      "metadata": {
        "id": "aBcDeFgHiJkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Verificación de Tipos de Datos y Nulos"
      ],
      "metadata": {
        "id": "LmNoPqRsTuVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Tipos de datos después de la limpieza ---\")\n",
        "df_cleaned.info()\n",
        "\n",
        "print(\"\\n--- Conteo de Nulos Restantes ---\")\n",
        "print(df_cleaned.isnull().sum())"
      ],
      "metadata": {
        "id": "MCxNzWbfwu2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Verificación de Integridad de Datos (Cálculo de Margen)"
      ],
      "metadata": {
        "id": "1Q3DEQvOvo-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['margen_calculado'] = df_cleaned['precio_venta'] - df_cleaned['precio_compra']\n",
        "df_cleaned['margen_diferencia'] = (df_cleaned['margen'] - df_cleaned['margen_calculado']).abs()\n",
        "\n",
        "discrepancies = df_cleaned[df_cleaned['margen_diferencia'] > 0.01] # Use tolerance for float precision\n",
        "\n",
        "print(f\"Se encontraron {len(discrepancies)} filas con una diferencia mayor a 0.01 entre el margen reportado y el calculado.\")"
      ],
      "metadata": {
        "id": "3mnhY3sA1g88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3. Resumen Estadístico del DataFrame Limpio"
      ],
      "metadata": {
        "id": "XyZ123AbCdEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_cleaned.describe(include='all').T)"
      ],
      "metadata": {
        "id": "azvap2mVwr1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4. Distribución de Variables Numéricas Limpias"
      ],
      "metadata": {
        "id": "J2YEissO3jWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['precio_compra', 'precio_venta', 'margen']:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
        "    fig.suptitle(f\"Análisis de la columna numérica limpia: '{col}'\", fontsize=16)\n",
        "\n",
        "    sns.histplot(df_cleaned[col], kde=True, ax=axes[0])\n",
        "    axes[0].set_title('Distribución (Histograma)')\n",
        "\n",
        "    sns.boxplot(x=df_cleaned[col], ax=axes[1])\n",
        "    axes[1].set_title('Diagrama de Caja (Boxplot)')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zUPalz6U2WnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Almacenamiento del DataFrame Limpio\n",
        "\n",
        "Se guarda el DataFrame limpio y validado en formato Parquet, que es eficiente para almacenamiento y análisis."
      ],
      "metadata": {
        "id": "_Wh7AW7evprf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop temporary columns used for verification before saving\n",
        "final_df_to_save = df_cleaned.drop(columns=['margen_calculado', 'margen_diferencia'])\n",
        "output_path = \"/content/drive/My Drive/Colab Notebooks/famiq_test/rentabilidad_productos_limpio.parquet\"\n",
        "\n",
        "# Ensure the pyarrow engine is installed for parquet support\n",
        "!pip install pyarrow -q\n",
        "\n",
        "final_df_to_save.to_parquet(output_path, index=False, engine='pyarrow')\n",
        "\n",
        "print(f\"DataFrame limpio con {len(final_df_to_save)} filas guardado exitosamente en: {output_path}\")"
      ],
      "metadata": {
        "id": "3Xc6m1KcvsdJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}