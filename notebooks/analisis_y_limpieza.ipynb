{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Exploratorio y Limpieza de Datos"
      ],
      "metadata": {
        "id": "eY11WrpEqoGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Configuración de entorno\n",
        "\n",
        "Se importan las librerías necesarias para el análisis y la manipulación de datos, y se monta Google Drive para acceder a los archivos."
      ],
      "metadata": {
        "id": "tOTAbfYWriw3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZc1UHWypjl0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "from google.colab import drive\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Carga de datos y limpieza de nombres de columnas\n",
        "Se define la ruta del archivo, se carga en un DataFrame y se normalizan inmediatamente los nombres de las columnas."
      ],
      "metadata": {
        "id": "sx6l4aKCqhWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/My Drive/Colab Notebooks/test/rentabilidad_productos.csv\"\n",
        "\n",
        "# Load the dataset\n",
        "df_raw = pd.read_csv(file_path)\n",
        "\n",
        "print(f\"DataFrame cargado con {df_raw.shape[0]} filas y {df_raw.shape[1]} columnas.\")\n",
        "\n",
        "# --- Initial column name cleaning ---\n",
        "original_cols = df_raw.columns.to_list()\n",
        "df_raw.columns = df_raw.columns.str.strip().str.lower().str.replace(' ', '_').str.replace(r'[^\\w\\s]', '', regex=True)\n",
        "cleaned_cols = df_raw.columns.to_list()\n",
        "\n",
        "print(\"\\n--- Normalización de Nombres de Columnas ---\")\n",
        "col_mapping = pd.DataFrame({'original': original_cols, 'limpio': cleaned_cols})\n",
        "display(col_mapping)"
      ],
      "metadata": {
        "id": "4t74GQZQqriZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Exploración Inicial\n",
        "\n",
        "Se pone el foco en entender la estructura y los tipos de datos del DataFrame."
      ],
      "metadata": {
        "id": "75fx-KeWsKrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Nombres de Columnas y Tipos de Datos\n",
        "Se obtiene un resumen del DataFrame."
      ],
      "metadata": {
        "id": "SEpIrynjsuGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.info()"
      ],
      "metadata": {
        "id": "oHlYtznHs0f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Visualización de Primeras y Últimas Filas\n",
        "Se muestran las primeras y últimas 5 filas del DataFrame."
      ],
      "metadata": {
        "id": "5hFSputls_ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Primeras 5 filas ---\")\n",
        "display(df_raw.head())\n",
        "\n",
        "print(\"\\n--- Últimas 5 filas ---\")\n",
        "display(df_raw.tail())"
      ],
      "metadata": {
        "id": "K49hku1WtKex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Resumen Estadístico\n",
        "Se genera un resumen estadístico para todas las columnas"
      ],
      "metadata": {
        "id": "Qj_M9I07tO7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_raw.describe(include='all').T)"
      ],
      "metadata": {
        "id": "Jg6wtnyNtVMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Análisis de Calidad de Datos\n",
        "\n",
        "Se investigan los problemas comunes de calidad de datos."
      ],
      "metadata": {
        "id": "dA0j6pMTuUZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Análisis de Valores Nulos\n",
        "\n",
        "Se cuantifican y visualizan los valores nulos."
      ],
      "metadata": {
        "id": "iy2TEtJzuZGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df_raw.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df_raw)) * 100\n",
        "missing_df = pd.DataFrame({'count': missing_values, 'percentage': missing_percentage})\n",
        "missing_df = missing_df[missing_df['count'] > 0].sort_values(by='count', ascending=False)\n",
        "\n",
        "print(f\"Se encontraron {len(missing_df)} columnas con valores nulos.\")\n",
        "display(missing_df)\n",
        "\n",
        "msno.matrix(df_raw)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1-es6YLXuT7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Análisis de Duplicados en Clave Primaria (SKU)\n",
        "\n",
        "Se identifican y cuentan los `sku` que aparecen más de una vez."
      ],
      "metadata": {
        "id": "CmmuR0dfuhf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sku_counts = df_raw.sku.value_counts()\n",
        "duplicated_skus = sku_counts[sku_counts > 1]\n",
        "\n",
        "print(f\"Análisis de duplicados de SKU:\")\n",
        "print(f\"- Hay {len(sku_counts)} SKUs únicos de un total de {len(df_raw)} registros.\")\n",
        "print(f\"- Se encontraron {len(duplicated_skus)} SKUs con registros duplicados.\")\n",
        "\n",
        "if not duplicated_skus.empty:\n",
        "    print(\"\\nTop 10 SKUs con más duplicados:\")\n",
        "    display(duplicated_skus.head(10).to_frame(name='count'))"
      ],
      "metadata": {
        "id": "iBL15PYRugq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3. Análisis de Formatos de Fecha\n",
        "Se examinan los valores únicos de `fecha_actualización` para identificar formatos inconsistentes."
      ],
      "metadata": {
        "id": "EXsUatIyz72k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"La columna 'fecha_actualización' tiene {df_raw.fecha_actualización.nunique()} valores únicos.\")\n",
        "print(\"\\nEjemplos de formatos encontrados:\")\n",
        "display(df_raw.fecha_actualización.value_counts().head(10).to_frame())"
      ],
      "metadata": {
        "id": "RUpw7Vq50B14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4. Análisis de Columnas Numéricas con Formato Incorrecto\n",
        "\n",
        "Se inspeccionan las columnas `precio_venta` y `margen` (tipo `object`) para encontrar caracteres no numéricos."
      ],
      "metadata": {
        "id": "K5lPb7a80mNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_check = ['precio_venta', 'margen']\n",
        "\n",
        "for col in cols_to_check:\n",
        "    # Find rows that contain non-numeric characters (excluding decimal point and minus sign)\n",
        "    problematic_rows = df_raw[df_raw[col].astype(str).str.contains(r'[^0-9.-]', regex=True, na=False)]\n",
        "    if not problematic_rows.empty:\n",
        "        print(f\"--- Análisis de la columna '{col}' ---\")\n",
        "        print(f\"Se encontraron {len(problematic_rows)} filas con caracteres no numéricos.\")\n",
        "        print(\"Ejemplos de valores problemáticos:\")\n",
        "        display(problematic_rows[col].head().to_frame())"
      ],
      "metadata": {
        "id": "31p3cFec0qQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.X. Análisis de Distribución y Outliers en Columnas Numéricas (revisar sección)\n",
        "\n",
        "Se generan histogramas y diagramas de caja (boxplots) para cada columna numérica."
      ],
      "metadata": {
        "id": "jWULX9IYvIje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df_raw.select_dtypes(include=np.number).columns\n",
        "\n",
        "for col in numeric_cols:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
        "    fig.suptitle(f\"Análisis de la columna numérica: '{col}'\", fontsize=16)\n",
        "\n",
        "    # Histogram\n",
        "    sns.histplot(df_raw[col], kde=True, ax=axes[0])\n",
        "    axes[0].set_title('Distribución (Histograma)')\n",
        "\n",
        "    # Boxplot\n",
        "    sns.boxplot(x=df_raw[col], ax=axes[1])\n",
        "    axes[1].set_title('Diagrama de Caja (Boxplot)')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "GYt7bhlevK9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.X. Análisis de Columnas Categóricas (revisar sección)\n",
        "\n",
        "Se examinan los valores únicos y su frecuencia en cada columna de tipo 'object'."
      ],
      "metadata": {
        "id": "A-6QruxquuBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = df_raw.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"--- Análisis de la columna: '{col}' ---\")\n",
        "    print(f\"Número de valores únicos: {df_raw[col].nunique()}\")\n",
        "    print(\"Frecuencia de los 10 valores más comunes:\")\n",
        "    display(df_raw[col].value_counts().nlargest(10))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "Q4LH7KVEuxZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Limpieza y Transformación de Datos\n",
        "\n",
        "Se aplica una serie de transformaciones basadas en los hallazgos anteriores para crear un DataFrame limpio."
      ],
      "metadata": {
        "id": "yx_8dH-lug67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy for cleaning to preserve the original dataframe\n",
        "df_cleaned = df_raw.copy()\n",
        "\n",
        "# --- 1. Limpiar y convertir columnas numéricas ---\n",
        "def clean_numeric(series):\n",
        "    return pd.to_numeric(series.astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce')\n",
        "\n",
        "df_cleaned['precio_venta'] = clean_numeric(df_cleaned['precio_venta'])\n",
        "df_cleaned['margen'] = clean_numeric(df_cleaned['margen'])\n",
        "\n",
        "# --- 2. Convertir columna de fecha ---\n",
        "df_cleaned['fecha_actualización'] = pd.to_datetime(df_cleaned['fecha_actualización'], errors='coerce', format='mixed')\n",
        "\n",
        "# --- 3. Limpiar espacios en columnas de texto ---\n",
        "for col in df_cleaned.select_dtypes(include=['object']).columns:\n",
        "    df_cleaned[col] = df_cleaned[col].str.strip()\n",
        "\n",
        "# --- 4. Manejar duplicados de SKU ---\n",
        "# Strategy: Keep the record with the most recent 'fecha_actualización'.\n",
        "initial_rows = len(df_cleaned)\n",
        "df_cleaned = df_cleaned.sort_values('fecha_actualización', ascending=False).drop_duplicates(subset='sku', keep='first')\n",
        "rows_removed = initial_rows - len(df_cleaned)\n",
        "print(f\"Se eliminaron {rows_removed} filas por duplicados de SKU, conservando la más reciente.\")\n",
        "\n",
        "# --- 5. Manejar valores nulos ---\n",
        "# Strategy: Fill 'categoria' with 'desconocida'. Drop rows where price or date is null as they are critical.\n",
        "df_cleaned['categoria'].fillna('desconocida', inplace=True)\n",
        "rows_before_na_drop = len(df_cleaned)\n",
        "df_cleaned.dropna(subset=['precio_compra', 'precio_venta', 'fecha_actualización'], inplace=True)\n",
        "na_rows_removed = rows_before_na_drop - len(df_cleaned)\n",
        "print(f\"Se eliminaron {na_rows_removed} filas por tener valores nulos en columnas críticas.\")\n",
        "\n",
        "print(\"\\n--- Verificación de tipos de datos después de la limpieza ---\")\n",
        "df_cleaned.info()"
      ],
      "metadata": {
        "id": "4lgtnlv6vaTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Verificación de Integridad de Datos\n",
        "\n",
        "Se calcula el margen (`precio_venta` - `precio_compra`) y se compara con la columna `margen` original para validar la consistencia."
      ],
      "metadata": {
        "id": "1Q3DEQvOvo-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['margen_calculado'] = df_cleaned['precio_venta'] - df_cleaned['precio_compra']\n",
        "df_cleaned['margen_diferencia'] = (df_cleaned['margen'] - df_cleaned['margen_calculado']).abs()\n",
        "\n",
        "discrepancies = df_cleaned[df_cleaned['margen_diferencia'] > 0.01] # Use tolerance for float precision\n",
        "\n",
        "print(f\"Se encontraron {len(discrepancies)} filas con una diferencia mayor a 0.01 entre el margen reportado y el calculado.\")\n",
        "\n",
        "if not discrepancies.empty:\n",
        "    print(\"\\nEjemplos de filas con discrepancias:\")\n",
        "    display(discrepancies[['sku', 'precio_compra', 'precio_venta', 'margen', 'margen_calculado']].head())\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.histplot(df_cleaned['margen_diferencia'], bins=50, kde=True)\n",
        "    plt.title('Distribución de la Diferencia Absoluta en el Margen')\n",
        "    plt.xlabel('Diferencia Absoluta')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3mnhY3sA1g88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Resumen Estadístico del DataFrame Limpio ---\")\n",
        "display(df_cleaned.describe(include='all').T)"
      ],
      "metadata": {
        "id": "azvap2mVwr1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Conteo de Nulos Restantes ---\")\n",
        "print(df_cleaned.isnull().sum())"
      ],
      "metadata": {
        "id": "MCxNzWbfwu2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Análisis de Datos Limpios\n",
        "Se realizan visualizaciones sobre el DataFrame limpio para evaluar."
      ],
      "metadata": {
        "id": "SraRGTyl2XDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1. Distribución de Variables Numéricas Limpias"
      ],
      "metadata": {
        "id": "J2YEissO3jWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols_cleaned = df_cleaned.select_dtypes(include=np.number).columns\n",
        "df_final = df_cleaned.drop(columns=['margen_calculado', 'margen_diferencia']) # Drop temporary columns for final analysis\n",
        "\n",
        "for col in ['precio_compra', 'precio_venta', 'margen']:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
        "    fig.suptitle(f\"Análisis de la columna numérica limpia: '{col}'\", fontsize=16)\n",
        "\n",
        "    sns.histplot(df_final[col], kde=True, ax=axes[0])\n",
        "    axes[0].set_title('Distribución (Histograma)')\n",
        "\n",
        "    sns.boxplot(x=df_final[col], ax=axes[1])\n",
        "    axes[1].set_title('Diagrama de Caja (Boxplot)')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zUPalz6U2WnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2. Correlación entre Variables Numéricas"
      ],
      "metadata": {
        "id": "0U7M7WvN3wzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = df_final[['precio_compra', 'precio_venta', 'margen']].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Mapa de Calor de Correlación de Variables Numéricas')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_8VH77vP3wJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Almacenamiento del DataFrame Limpio\n",
        "\n",
        "Se guarda el DataFrame limpio y validado en formato Parquet.\n"
      ],
      "metadata": {
        "id": "_Wh7AW7evprf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df_to_save = df_cleaned.drop(columns=['margen_calculado', 'margen_diferencia'])\n",
        "output_path = \"/content/drive/My Drive/Colab Notebooks/famiq_test/rentabilidad_productos_limpio.parquet\"\n",
        "\n",
        "# Ensure the pyarrow engine is installed for parquet support\n",
        "!pip install pyarrow -q\n",
        "\n",
        "final_df_to_save.to_parquet(output_path, index=False, engine='pyarrow')\n",
        "\n",
        "print(f\"DataFrame limpio con {len(final_df_to_save)} filas guardado exitosamente en: {output_path}\")"
      ],
      "metadata": {
        "id": "3Xc6m1KcvsdJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}