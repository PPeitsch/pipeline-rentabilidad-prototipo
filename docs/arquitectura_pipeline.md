# Arquitectura del Pipeline de Datos:

Patr√≥n de dise√±o por capas.

## 1. Arquitectura ELT

Se utiliza el siguiente stack disponible para implementar el pipeline **ELT (Extract, Load, Transform)**. En este modelo, los datos se extraen de las fuentes y se cargan casi en crudo en el data warehouse, donde se realizan las transformaciones.

**Flujo de Datos:**

```mermaid
graph LR
    %% Define styles for different component types
    classDef orchestrator fill:#fffbe6,stroke:#ffc107,stroke-width:2px;
    classDef source fill:#e3f2fd,stroke:#2196f3,stroke-width:2px;
    classDef platform fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px;
    classDef bi fill:#e8f5e9,stroke:#4caf50,stroke-width:2px;
    classDef tool fill:#eceff1,stroke:#607d8b,stroke-width:1.5px,stroke-dasharray: 5 5;

    %% Main Orchestrator (Control Plane)
    subgraph "Plano de Orquestaci√≥n"
        Airflow("üí® Airflow")
    end

    %% Data Plane
    subgraph "Plano de Datos"
        direction LR

        subgraph "1. Sistema Fuente"
            MySQL("üóÑÔ∏è MySQL")
        end

        subgraph "2. Plataforma Anal√≠tica"
            subgraph "Data Lake (Backup)"
                BronzeLake["üíæ<br>Capa Bronze<br>(Parquet)"]
            end
            subgraph "Data Warehouse (ClickHouse)"
                RawWH["üì•<br>Datos Crudos"] --> SilverWH["‚ú®<br>Capa Silver<br>(Limpios)"] --> GoldWH["üèÜ<br>Capa Gold<br>(Agregados)"]
            end
        end

        subgraph "3. Consumo de Datos"
            BI["üìä Metabase / Superset"]
        end
    end

    %% Tooling Layer (as enablers of the flow)
    Airbyte("üîÑ Airbyte")
    DBT("‚öôÔ∏è dbt")
    Elementary("‚úîÔ∏è Elementary")

    %% Define Data Flow
    MySQL -- "Carga de datos" --> Airbyte
    Airbyte -- "Destino 1" --> BronzeLake
    Airbyte -- "Destino 2" --> RawWH
    SilverWH -- "Transformaci√≥n" --> DBT
    DBT -- "Crea/Actualiza modelos" --> GoldWH
    GoldWH -- "Consultas de BI" --> BI

    %% Define Control Flow (Orchestration & Monitoring)
    Airflow -.-> Airbyte
    Airflow -.-> DBT
    DBT -. "Ejecuta tests" .-> Elementary
    Elementary -. "Reporta estado" .-> Airflow

    %% Apply styles
    class Airflow orchestrator;
    class MySQL source;
    class BronzeLake,RawWH,SilverWH,GoldWH platform;
    class BI bi;
    class Airbyte,DBT,Elementary tool;

    %% Style links
    linkStyle 1,2,3,4,5 stroke-width:2px,fill:none,stroke:#333;
    linkStyle 6,7,8,9 stroke-width:2px,fill:none,stroke:#ff9800,stroke-dasharray: 4 4;
```

**Etapas del Pipeline**

0.  **An√°lisis Exploratorio de Datos:**
    *   **Prop√≥sito:** La fase inicial de an√°lisis sobre una muestra de datos (`rentabilidad_productos.csv`) revel√≥ varios problemas de calidad de datos. Estos hallazgos son la base para definir las reglas de transformaci√≥n que se implementar√°n en la etapa (T) con dbt.
    *   **Hallazgos Clave a Resolver:**
        *   **Nombres de Columnas:** Inconsistentes, con espacios, may√∫sculas y caracteres especiales. Deben normalizarse (ej. 'Precio Venta' -> `precio_venta`).
        *   **Tipos de Datos Incorrectos:** Columnas num√©ricas cr√≠ticas como `precio_venta` y `margen` estaban almacenadas como texto (`object`) debido a caracteres no v√°lidos.
        *   **Formatos de Fecha Inconsistentes:** La columna `fecha_actualizacion` conten√≠a m√∫ltiples formatos de fecha, impidiendo su uso correcto en operaciones temporales.
        *   **Duplicados de Clave Primaria:** M√∫ltiples registros para el mismo `sku`, requiriendo una estrategia de desduplicaci√≥n (ej. conservar el registro con la `fecha_actualizacion` m√°s reciente).
        *   **Valores Nulos:** Presencia de nulos en columnas importantes como `categoria`, que deben ser manejados (ej. imputar con un valor 'desconocida').
        *   **Espacios en Blanco:** Columnas de texto con espacios sobrantes al inicio o al final, afectando la consistencia de los datos categ√≥ricos.

1.  **Extracci√≥n y Carga (EL) con Airbyte:**
    *   **Herramienta:** **Airbyte**.
    *   **Flujo:** Airbyte se conecta directamente a la base de datos de producci√≥n (**MySQL**). Se configura para extraer los datos de las tablas relevantes (ej. `productos`, `ventas`).
    *   **Destino:** Airbyte carga estos datos en dos lugares simult√°neamente:
        1.  Al **Data Lake** como archivos Parquet particionados. Esto crea la capa **Bronze**, para respaldo y reprocesamientos hist√≥ricos.
        2.  A un esquema de datos crudos (`raw_data`) en **ClickHouse**. Esto prepara los datos para la transformaci√≥n inmediata.

2.  **Almacenamiento con Data Lake y ClickHouse:**
    *   **Data Lake (Capa Bronze):** Repositorio para los datos crudos extra√≠dos por Airbyte.
    *   **Data Warehouse (Capas Silver y Gold):** **ClickHouse** es el motor anal√≠tico. Ideal para las transformaciones y consultas de BI. Contendr√° los datos limpios (Silver) y agregados (Gold).

3.  **Transformaci√≥n (T) con dbt:**
    *   **Herramienta:** **dbt (Data Build Tool)**.
    *   **Flujo:** dbt se conecta a ClickHouse. Lee los datos del esquema `raw_data` y ejecuta una serie de modelos SQL para:
        *   **Limpiar y estandarizar:** Aplica la l√≥gica descubierta en el notebook (normalizaci√≥n de nombres, conversi√≥n de tipos, limpieza de texto, estandarizaci√≥n de fechas).
        *   **Desduplicar y modelar:** Aplica la l√≥gica de negocio para consolidar registros (ej. quedarse con el SKU m√°s reciente) y crea modelos de datos limpios y conformados (tablas de dimensiones y hechos).
        *   **Agregar:** Crea tablas agregadas finales (ej. `agg_rentabilidad_por_proveedor`) optimizadas para las consultas de BI.

4.  **Calidad y Observabilidad con Elementary:**
    *   **Herramienta:** **Elementary Data**.
    *   **Integraci√≥n:** Se puede integrar con Airflow, dbt, ClickHouse, Metabase. Definir pruebas de calidad de datos avanzadas sobre los modelos. Elementary Data va a monitorear los resultados de las pruebas (`dbt test`) con el fin de detectar anomal√≠as en los datos (ej. ca√≠das de volumen, aumento de nulos), proporcionando una capa de observabilidad adicional en el proceso.

5.  **Orquestaci√≥n con Airflow:**
    *   **Herramienta:** **Airflow**.
    *   **Flujo:** Un DAG de Airflow orquesta todo el proceso, gestionando las dependencias:
        1.  Inicia la tarea de sincronizaci√≥n en **Airbyte**.
        2.  Al completarse, ejecuta los modelos de transformaci√≥n con `dbt run`.
        3.  A continuaci√≥n, ejecuta las pruebas de calidad de datos con `dbt test`.
        4.  Gestiona reintentos y env√≠a alertas en caso de fallo.

6.  **Visualizaci√≥n y BI con Superset / Metabase:**
    *   **Herramientas:** **Metabase**.
    *   **Flujo:** Se conecta directamente a las tablas de la capa **Gold** en **ClickHouse** para que los usuarios de negocio puedan explorar datos, crear dashboards y generar reportes.

## 2. Estrategia de Almacenamiento

La Arquitectura Medallion se mantiene, pero ahora con herramientas asignadas.

1.  **Zona Bronze (Raw Data - Datos Crudos):**
    *   **Ubicaci√≥n:** Data Lake (almacenamiento de objetos como S3, GCS).
    *   **Poblado por:** **Airbyte**.
    *   **Formato:** **Parquet**, particionado por fecha de carga (`load_date=YYYY-MM-DD`).
    *   **Prop√≥sito:** Copia exacta e inmutable de la fuente. Permite la recuperaci√≥n ante desastres y el reprocesamiento completo del pipeline sin volver a consultar MySQL.

2.  **Zona Silver (Cleansed & Conformed Data - Datos Limpios):**
    *   **Ubicaci√≥n:** Esquema `silver` en **ClickHouse**.
    *   **Creado por:** Modelos de **dbt**.
    *   **Prop√≥sito:** Contiene los datos despu√©s de aplicar la l√≥gica de limpieza que prototipamos en el notebook: tipos de datos corregidos, cadenas estandarizadas, SKUs desduplicados seg√∫n la fecha m√°s reciente, nulos manejados. Es la fuente de verdad para el an√°lisis.

3.  **Zona Gold (Curated Business-Level Data - Datos Agregados de Negocio):**
    *   **Ubicaci√≥n:** Esquema `gold` en **ClickHouse**.
    *   **Creado por:** Modelos de agregaci√≥n de **dbt** que leen de la capa Silver.
    *   **Prop√≥sito:** Tablas pre-agregadas y optimizadas para los casos de uso de negocio. Son las tablas que alimentar√°n directamente los dashboards en **Superset/Metabase**, garantizando un rendimiento √≥ptimo.

## 3. Consideraciones Operativas con el Stack Espec√≠fico

### Frecuencia de Ejecuci√≥n

*   **Recomendaci√≥n:** Batch diario, programado y ejecutado por un **DAG de Airflow**. Se ejecuta en horas de baja carga para minimizar el impacto en MySQL.

### Manejo de Errores y Reintentos

*   **Reintentos Autom√°ticos:** El **DAG de Airflow** se configurar√° con reintentos y esperas para manejar fallos transitorios en cualquier etapa (Airbyte, dbt).

### Monitoreo y Alertas

*   **Monitoreo de Ejecuci√≥n:** La UI de **Airflow** proporciona un monitoreo detallado del estado de cada tarea del pipeline (√©xito, fallo, duraci√≥n). Airflow puede configurarse para enviar alertas (ej. a Slack o email) en caso de fallo del DAG.
*   **Monitoreo de Calidad de Datos:** **Elementary** ser√° nuestra herramienta principal aqu√≠. Se integra con `dbt test` y nos alertar√° proactivamente sobre problemas de calidad (ej. un `sku` que ya no es √∫nico, un aumento an√≥malo de nulos) directamente en Slack, con contexto y linaje de datos.
